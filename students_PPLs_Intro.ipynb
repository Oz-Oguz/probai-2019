{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "students_PPLs_Intro.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "probabilistic.ai",
      "language": "python",
      "name": "probabilistic.ai"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oz-Oguz/probai-2019/blob/master/students_PPLs_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7obzySjmeHm9",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "Let's begin by importing the modules we'll need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2lHESwteHm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "30854897-0bbb-4733-b949-72c643fe0163"
      },
      "source": [
        "!pip install -q pyro-ppl torch\n",
        "import pyro\n",
        "import torch\n",
        "import pyro.distributions as dist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 235kB 1.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 20.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 18.7MB/s \n",
            "\u001b[?25h  Building wheel for pyro-ppl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyvIwHB0eHnB",
        "colab_type": "text"
      },
      "source": [
        "# 1. Pyro’s distributions (http://docs.pyro.ai/en/stable/distributions.html) :\n",
        "\n",
        "Pyro provides a wide range of distributions: Normal, Beta, Cauchy, Dirichlet, Gumbel, Poisson,\n",
        "Pareto, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbzErc0UeHnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "255cdf2b-490d-4397-fe74-885ded83f45c"
      },
      "source": [
        "normal = dist.Normal(0,1)\n",
        "normal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normal(loc: 0.0, scale: 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZoluoT3eHnF",
        "colab_type": "text"
      },
      "source": [
        "Samples from the distributions are [Pytorch’s Tensor objects](https://pytorch.org/cppdocs/notes/tensor_creation.html) (i.e. multidimensional arrays).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOTnOrDpeHnG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "790024ba-6633-46a4-f734-0cabdbe9953d"
      },
      "source": [
        "sample = normal.sample()\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0330)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtGemMfgeHnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "e5c5d90b-74fc-4be0-aeeb-2c9722db2562"
      },
      "source": [
        "sample = normal.sample(sample_shape=[3,4,5])\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8968,  0.8650, -1.4452, -0.7400,  1.5299],\n",
              "         [-0.1478,  0.3973,  0.7450, -0.0135,  2.2088],\n",
              "         [-0.4158,  0.0063,  1.0019, -0.6700, -2.7622],\n",
              "         [ 0.6801, -0.5287,  0.0693,  0.1497, -1.3805]],\n",
              "\n",
              "        [[-1.3687,  0.3494,  0.6770,  0.3039, -0.0412],\n",
              "         [-1.5637,  1.1083,  0.9388, -2.1368, -0.1984],\n",
              "         [ 0.8087,  0.2601,  0.8026, -0.6346,  1.0117],\n",
              "         [ 0.5873,  1.5172,  0.4246, -0.3721, -0.6412]],\n",
              "\n",
              "        [[ 0.4502,  0.2937, -0.2959, -0.0487,  0.0725],\n",
              "         [ 0.2780,  0.8795, -0.4629,  1.1445,  0.8155],\n",
              "         [ 0.9772,  0.4723, -0.8445,  0.2267,  1.3146],\n",
              "         [-2.1879,  0.8964, -0.7292,  2.2834,  0.6510]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxWipPAMeHnM",
        "colab_type": "text"
      },
      "source": [
        "We can query the dimensionlity of a tensor with the ``shape`` property"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLuzf2AMeHnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e722ce93-53b2-4e49-ab44-8c041bb55a07"
      },
      "source": [
        "sample = normal.sample(sample_shape=[3,4,5])\n",
        "sample.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYmtwty2eHnR",
        "colab_type": "text"
      },
      "source": [
        "Operations, like log-likelihood, are defined over tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1z4X9pWeHnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6b8719b7-93c0-4470-b142-68b945b112f2"
      },
      "source": [
        "normal.log_prob(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9630, -1.0675, -0.9194, -0.9304, -4.6844],\n",
              "         [-2.2850, -2.0771, -1.1297, -0.9469, -1.2164],\n",
              "         [-1.4978, -0.9579, -1.1295, -1.1393, -1.2935],\n",
              "         [-1.2955, -0.9263, -0.9730, -1.6940, -2.6085]],\n",
              "\n",
              "        [[-0.9192, -1.4777, -0.9207, -1.4865, -1.1468],\n",
              "         [-1.0429, -2.2629, -1.2295, -3.3545, -1.0827],\n",
              "         [-1.5073, -0.9469, -1.0009, -3.3480, -2.6336],\n",
              "         [-1.1638, -1.6251, -1.2057, -1.1582, -0.9200]],\n",
              "\n",
              "        [[-1.0576, -0.9191, -1.0210, -1.1834, -1.0367],\n",
              "         [-0.9196, -1.4734, -1.0472, -0.9789, -1.6692],\n",
              "         [-1.3740, -0.9553, -1.0622, -0.9255, -0.9255],\n",
              "         [-1.0844, -1.4293, -2.7456, -2.6715, -0.9464]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZrSU4oXeHnV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0018f037-db1d-48ca-efc8-63979df936af"
      },
      "source": [
        "torch.sum(normal.log_prob(sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-85.5939)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qDNIbqeHnY",
        "colab_type": "text"
      },
      "source": [
        "Multiple distributions can be embedded in single object, as shown in this example, where three Normal distributions with different means and same scale are defined in a single object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9oURJbYeHnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b49cbab-66a4-410f-cf12-23182e84806f"
      },
      "source": [
        "normal = dist.Normal(torch.tensor([1.,2.,3.]),1.)\n",
        "normal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normal(loc: torch.Size([3]), scale: torch.Size([3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-w7H-80eHnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dd813a7-5b31-458f-a2ad-c4b4f6461e00"
      },
      "source": [
        "normal.sample()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2667,  1.7360,  3.1929])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n40efV9beHnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "631044e6-c835-4a60-e9a7-d37eceeffb68"
      },
      "source": [
        "normal.log_prob(normal.sample())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.7691, -2.0865, -1.5843])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjq1NX3zeHnp",
        "colab_type": "text"
      },
      "source": [
        "# 2. Pyro’s model (http://pyro.ai/examples/intro_part_i.html) :\n",
        "\n",
        "\n",
        "* In Pyro, a probabilistic model is defined as a stochastic function (i.e. every time is run, it returns a new sample).\n",
        "\n",
        "* Each random variable is associated to a primitive stochastic function using the construct ``pyro.sample(...)``.\n",
        "\n",
        "\n",
        "\n",
        "### 2.1 A Temperature Model \n",
        "\n",
        "\n",
        "\n",
        "As initial running example, we consider the problem of modelling the temperature. We first start with a simple model where temperture is modeled using a random Normal variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cKjRT01eHnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bde5f7c9-0839-457a-d316-abaafacc8a4f"
      },
      "source": [
        "def model():\n",
        "    temp = pyro.sample('temp', dist.Normal(15.0, 2.0))\n",
        "    return temp\n",
        "\n",
        "print(model())\n",
        "print(model())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(17.4282)\n",
            "tensor(14.8969)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuGCVBqbeHnu",
        "colab_type": "text"
      },
      "source": [
        "See how the model is a stochastic function which returns a different value everytime is invoked. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqSypn-YeHnv",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 A Temperature-Sensor Model\n",
        "\n",
        "* In Pyro, an stochastic method is defined as a **composition of primitive stochastic functions**.\n",
        "\n",
        "In the following example, we introduce the presence of a sensor, which is the one which is giving observations about the real temperature. In this case, we assume the sensor provides unbiased measurments of the temperature (i.e. the mean of the sensor's readings are the real temperature) and the error of the sensor's measurements is known."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCPfs8NeeHnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a58be608-1c3c-47b4-a1cd-a386d5576c44"
      },
      "source": [
        "def model():\n",
        "    temp = pyro.sample('temp', dist.Normal(15.0, 2.0))\n",
        "    sensor = pyro.sample('sensor', dist.Normal(temp, 1.0))\n",
        "    return (temp, sensor)\n",
        "\n",
        "out1 = model()\n",
        "out1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(16.6831), tensor(15.4458))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWShVwsseHnz",
        "colab_type": "text"
      },
      "source": [
        "The above method defines a joint probability distribution:\n",
        "$$p(sensor, temp) = p(sensor|temp)p(temp)$$\n",
        "\n",
        "A graphical description of this model, in terms of probabilistic graphical models, would be as follows:\n",
        "\n",
        "<img src=\"slides/Figures/PGM-Tem-Sensor.png\" alt=\"Drawing\" style=\"width: 150px;\" >\n",
        "\n",
        "\n",
        "In this case, we have a simple dependency between the variables. But, as we are in a PPL, dependencies can be expressed in terms of complex deterministic functions (more examples later)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx5eTE4leHn0",
        "colab_type": "text"
      },
      "source": [
        "# 3. Pyro’s inference (http://pyro.ai/examples/intro_part_ii.html) :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQriYZ1SeHn0",
        "colab_type": "text"
      },
      "source": [
        "### Auxiliary inference functions (more details on Day 3)\n",
        "\n",
        "To make inference on Pyro, we will use a variational inference method, which performs gradient-based optimization to solve the inference problem. More details will be given on Day 3. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVnI3trDeHn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.distributions import constraints\n",
        "from pyro.optim import SGD\n",
        "from pyro.infer import Trace_ELBO\n",
        "import matplotlib.pyplot as plt\n",
        "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
        "\n",
        "\n",
        "def svi(temperature_model, guide, obs, num_steps = 5000, plot = False):\n",
        "    pyro.clear_param_store()\n",
        "    svi = pyro.infer.SVI(model=temperature_model,\n",
        "                         guide=guide,\n",
        "                         optim=SGD({\"lr\": 0.001, \"momentum\":0.1}),\n",
        "                         loss=Trace_ELBO())\n",
        "\n",
        "    losses, a,b  = [], [], []\n",
        "    \n",
        "    for t in range(num_steps):\n",
        "        losses.append(svi.step(obs))\n",
        "\n",
        "    if (plot):\n",
        "        plt.plot(losses)\n",
        "        plt.title(\"ELBO\")\n",
        "        plt.xlabel(\"step\")\n",
        "        plt.ylabel(\"loss\");\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY0BNv0meHn3",
        "colab_type": "text"
      },
      "source": [
        "### 3.1  Conditioning on a single observation\n",
        "\n",
        "Now, we continue with the last model defined in section 2.2, and assume we have a sensor reading and we want to compute the posterior distribution over the real temperature. \n",
        "\n",
        "\n",
        "* When defining the model we can introduce observations in a random variable with the keyword ``obs=``.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK3JbkT_eHn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor(18.0)}\n",
        "\n",
        "def model(obs):\n",
        "    temp = pyro.sample('temp', dist.Normal(15.0, 2.0))\n",
        "    sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTwstO-ZeHn6",
        "colab_type": "text"
      },
      "source": [
        "To make inference in Pyro over a given model we need to define a *guide*, this *guide* has the same signature than its counterpart model. And the guide must provide samples for those variables of the model which are not observed using again the ``pyro.sample`` construct. Guides are also parametrized using Pyro's parameters (``pyro.param``), so the variational inference algorithm will optimize these parameters. All of that will be explained in detail on Day 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8vhgxuaeHn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The guide\n",
        "def guide(obs):\n",
        "    a = pyro.param(\"mean\", torch.tensor(0.0))\n",
        "    b = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    temp = pyro.sample('temp', dist.Normal(a, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekQrscjHeHn9",
        "colab_type": "text"
      },
      "source": [
        "Now, we can perform inference making use the previously defined auxiliary functions, ``svi`` and ``guide``, and query the posterior probability distribution: \n",
        "\n",
        "\n",
        "$$p(temp | sensor=18)=\\frac{p(sensor=18|temp)p(temp)}{\\int p(sensor=18|temp)p(temp) dtemp}$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sERuzk3eHn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "1133e1cb-eb4a-4ea3-ebda-f6739534935b"
      },
      "source": [
        "#Run inference\n",
        "svi(model,guide,obs, plot=True)\n",
        "\n",
        "#Print results\n",
        "print(\"P(Temperature|Sensor=18.0) = \")\n",
        "print(dist.Normal(pyro.param(\"mean\").item(), pyro.param(\"scale\").item()))\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "P(Temperature|Sensor=18.0) = \n",
            "Normal(loc: 17.340776443481445, scale: 0.9197695255279541)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH2S_FKCeHoA",
        "colab_type": "text"
      },
      "source": [
        "Above we can see the result of the inference, and also how the ELBO function is minimized during the variational inference process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks2tpfHNeHoB",
        "colab_type": "text"
      },
      "source": [
        "### 3.2  Learning from a bunch of observations\n",
        "\n",
        "In this case, we assume we have a bunch of observations about the temperature at different time steps. In this case, following a probabilistic modelling approach, we define a bunch of random variables, one for each observation, using a standard ``for-loop``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlShbwTfeHoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
        "\n",
        "def model(obs):\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        temp = pyro.sample(f'temp_{i}', dist.Normal(15.0, 2.0))\n",
        "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwJStmRVeHoD",
        "colab_type": "text"
      },
      "source": [
        "On the other side, we are not sure about the mean temperature and we want to infer it from the data. For doing that we can follow a *maximum likelihood* approach,\n",
        "\n",
        "$$ \\mu_{t} = \\arg\\max_\\mu \\ln p(s_1,\\ldots,s_n|\\mu) = \\arg\\max_\\mu \\prod_i \\int_{t_i} p(s_i|t_i)p(t_i|\\mu) dt_i $$\n",
        "where $s_i$ denotes the sensor readings, $t_i$ is the real temperature at time $i$. \n",
        "\n",
        "However, with PPLs, we do not have to care about the underlying inference problem. We just define the model and let the PPL's engine make the work for us. So the model is defined as follows, using Pyro's parameters (defined as ``pyro.param``), which are free variables we can optimize. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-tJhDgCeHoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.param('mean_temp', torch.tensor(15.0))\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_temp, 2.0))\n",
        "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCmXp1C7eHoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the guide\n",
        "def guide(obs):\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        mean_i = pyro.param(f'mean_{i}', obs['sensor'][i])\n",
        "        scale_i = pyro.param(f'scale_{i}', torch.tensor(1.), constraint=constraints.positive)\n",
        "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_i, scale_i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LImrHy0feHoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65950559-9afc-4935-ad66-cb7c65c3c9d9"
      },
      "source": [
        "#Run inference\n",
        "svi(model, guide, obs, num_steps=1000)\n",
        "\n",
        "#Print results\n",
        "print(\"Estimated Mean Temperature\")\n",
        "print(pyro.param(\"mean_temp\").item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated Mean Temperature\n",
            "19.107908248901367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Uh_okheHoL",
        "colab_type": "text"
      },
      "source": [
        "Instead of performing *maximum likelihood* learning, we can perform *Bayesian learning* and treat the unknown as a random variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3L6Kv1JeHoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_temp, 2.0))\n",
        "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeBcccc4eHoP",
        "colab_type": "text"
      },
      "source": [
        "The above model can be graphically represented as follows:\n",
        "\n",
        "<img src=\"slides/Figures/PGM-Tem-Sensor2.png\" alt=\"Drawing\" style=\"width: 250px;\" >\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We perform inference over this model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NvyiajreHoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the guide\n",
        "def guide(obs):\n",
        "    mean = pyro.param(\"mean\", torch.mean(obs['sensor']))\n",
        "    scale = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(mean, scale))\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        mean_i = pyro.param(f'mean_{i}', obs['sensor'][i])\n",
        "        scale_i = pyro.param(f'scale_{i}', torch.tensor(1.), constraint=constraints.positive)\n",
        "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_i, scale_i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xyiPZkKeHoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9de0f68a-468e-4b84-e42f-455458324acf"
      },
      "source": [
        "import time\n",
        "        \n",
        "#Run inference\n",
        "start = time.time()\n",
        "svi(model, guide, obs, num_steps=1000)\n",
        "\n",
        "#Print results\n",
        "print(\"P(mean_temp|Sensor=[18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]) =\")\n",
        "print(dist.Normal(pyro.param(\"mean\").item(), pyro.param(\"scale\").item()))\n",
        "print(\"\")\n",
        "end = time.time()\n",
        "print(f\"{(end - start)} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(mean_temp|Sensor=[18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]) =\n",
            "Normal(loc: 19.29204750061035, scale: 0.6448507308959961)\n",
            "\n",
            "10.467576026916504 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGVMbjoneHoU",
        "colab_type": "text"
      },
      "source": [
        "Now, the result of the learning is not a *point estimate*, but a *posterior distribution* which captures uncertainty about the estimation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO1Y4yrIeHoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "ada360f3-b3cd-48d7-a60b-0f39005bd0ff"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "mu = 19.312837600708008\n",
        "scale = 0.6332376003265381\n",
        "x = np.linspace(mu - 3*scale, mu + 3*scale, 100)\n",
        "plt.plot(x, stats.norm.pdf(x, mu, scale), label='Posterior')\n",
        "point = 19.123859405517578\n",
        "plt.plot([point, point],[0., 1.], label='Point Estimate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0S4K4teeHoX",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 The use of ``plate`` construct\n",
        "\n",
        "In this new example, we will tell Pyro how to exploit conditional independencies and vectorization to make inference much faster. This can be done with the construct ``palte``. With this construct we can indicate the variables $s_i$ and $t_i$ are conditionally indepdendent from another variables $s_j$ and $t_j$ given $\\mu_t$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsmdd0OGeHoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
        "    with pyro.plate('a', obs['sensor'].shape[0]):\n",
        "        temp = pyro.sample('temp', dist.Normal(mean_temp, 2.0))\n",
        "        sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_rxRRCheHoa",
        "colab_type": "text"
      },
      "source": [
        "The ``plate`` construct refers to the standard notation use in graphical models to denote the repetition of some parts of of the graph. In this way this Pyro model can be graphically represented as follows, \n",
        "\n",
        "<img src=\"slides/Figures/PGM-Tem-Sensor3.png\" alt=\"Drawing\" style=\"width: 250px;\" >\n",
        "\n",
        "Here we can also observe the distintion between **local** and **global** rando variables. The former caputures information which is specific about the $i$-th data sample (i.e. the real temperature at this moment in time), while the latter captures information which is common about all the data samples (i.e. the average temperature across all data samples). \n",
        "\n",
        "\n",
        "Observe how inference in this model is much faster. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6YbzITDeHoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the guide\n",
        "def guide(obs_sensor):\n",
        "    mean = pyro.param(\"mean\", torch.mean(obs['sensor']))\n",
        "    scale = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(mean, scale))\n",
        "    with pyro.plate('a', obs['sensor'].shape[0]) as i:\n",
        "        mean_i = pyro.param('mean_i', obs['sensor'][i])\n",
        "        scale_i = pyro.param('scale_i', torch.tensor(1.), constraint=constraints.positive)\n",
        "        temp = pyro.sample('temp', dist.Normal(mean_i, scale_i))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNjH1wY-eHof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2db859db-1b7e-4264-adf8-49281d119d74"
      },
      "source": [
        "#Run inference\n",
        "start = time.time()\n",
        "svi(model, guide, obs, num_steps=1000)\n",
        "\n",
        "#Print results\n",
        "print(\"P(mean_temp|Sensor=[18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]) =\")\n",
        "print(dist.Normal(pyro.param(\"mean\").item(), pyro.param(\"scale\").item()))\n",
        "print(\"\")\n",
        "end = time.time()\n",
        "print(f\"{(end - start)} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(mean_temp|Sensor=[18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]) =\n",
            "Normal(loc: 19.323226928710938, scale: 0.6226696372032166)\n",
            "\n",
            "2.7858188152313232 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6KTmswZeHoj",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:red\">Exercise 1: </span>The role of *prior distributions* in learning\n",
        "\n",
        "In this case we just want to llustrate how the output of learning depends of the particular prior we introduce in the model. Play with different options and extract conclusions:\n",
        "\n",
        "1. What happens if we change the mean of the prior?\n",
        "2. What happens if we change the scale of the prior?\n",
        "3. What happens to the posterior if the number of data samples deacreases and increases?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SELXqT5YeHom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5b308265-3a1c-41ff-d35f-30c21da696fd"
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
        "    with pyro.plate('a', obs['sensor'].shape[0]):\n",
        "        temp = pyro.sample('temp', dist.Normal(mean_temp, 2.0))\n",
        "        sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])\n",
        "\n",
        "#Run inference\n",
        "svi(model, guide, obs, num_steps=1000)\n",
        "\n",
        "#Print results\n",
        "print(\"P(Temperature|Sensor=18.0) = \")\n",
        "print(dist.Normal(pyro.param(\"mean\").item(), pyro.param(\"scale\").item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(Temperature|Sensor=18.0) = \n",
            "Normal(loc: 19.291288375854492, scale: 0.6071039438247681)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svvSexhheHor",
        "colab_type": "text"
      },
      "source": [
        "# 4.  Icecream Shop\n",
        "\n",
        "Imagine we have an ice-cream shop and we record the ice-cream sales and the average temperature of the day (using a temperature sensor), because we know the temperature influences the sales. We want to precisely find out how temperature affects ice-cream sales. \n",
        "\n",
        "<img src=\"slides/Figures/Ice-cream_shop_-_Florida.jpg\" alt=\"Drawing\" style=\"width: 600px;\" >\n",
        "\n",
        "\n",
        "We assume that the daily sales follows a Poisson distribution, whose mean parameter linearly depends on the real temperature of the day. The coefficients of this linear relationship are modelled as random variables. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xohgB0PKeHor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]),\n",
        "       'sales': torch.tensor([46., 47., 49., 44., 50., 54., 51., 52., 49., 53.])}\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
        "    alpha = pyro.sample('alpha', dist.Normal(0.0, 100.0))\n",
        "    beta = pyro.sample('beta', dist.Normal(0.0, 100.0))\n",
        "\n",
        "    with pyro.plate('a', obs['sensor'].shape[0]):\n",
        "        temp = pyro.sample('temp', dist.Normal(mean_temp, 2.0))\n",
        "        sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])\n",
        "        rate = torch.max(torch.tensor(0.001), alpha + beta*temp)\n",
        "        sales = pyro.sample('sales', dist.Poisson(rate), obs=obs['sales'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyXjf8DKeHou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the guide\n",
        "def guide(obs):\n",
        "    mean = pyro.param(\"mean\", torch.mean(obs['sensor']))\n",
        "    scale = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(mean, scale))\n",
        "\n",
        "    alpha_mean = pyro.param(\"alpha_mean\", torch.mean(obs['sensor']))\n",
        "    alpha_scale = pyro.param(\"alpha_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    alpha = pyro.sample('alpha', dist.Normal(alpha_mean, alpha_scale))\n",
        "\n",
        "    beta_mean = pyro.param(\"beta_mean\", torch.tensor(1.0))\n",
        "    beta_scale = pyro.param(\"beta_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    beta = pyro.sample('beta', dist.Normal(beta_mean, beta_scale))\n",
        "\n",
        "    with pyro.plate('a', obs['sensor'].shape[0]) as i:\n",
        "        mean_i = pyro.param('mean_i', obs['sensor'][i])\n",
        "        scale_i = pyro.param('scale_i', torch.tensor(1.), constraint=constraints.positive)\n",
        "        temp = pyro.sample('temp', dist.Normal(mean_i, scale_i))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoPiq1Z_eHoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a2e72daa-7d19-45ba-f15b-c44e98fe7aa2"
      },
      "source": [
        "#Run inference\n",
        "svi(model, guide, obs, num_steps=1000)\n",
        "\n",
        "#Print results    \n",
        "print(\"Posterior Temperature Mean\")\n",
        "print(dist.Normal(pyro.param(\"mean\").item(), pyro.param(\"scale\").item()))\n",
        "print(\"\")\n",
        "print(\"Posterior Alpha\")\n",
        "print(dist.Normal(pyro.param(\"alpha_mean\").item(), pyro.param(\"alpha_scale\").item()))\n",
        "print(\"\")\n",
        "print(\"Posterior Beta\")\n",
        "print(dist.Normal(pyro.param(\"beta_mean\").item(), pyro.param(\"beta_scale\").item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Posterior Temperature Mean\n",
            "Normal(loc: 19.284452438354492, scale: 0.6163542866706848)\n",
            "\n",
            "Posterior Alpha\n",
            "Normal(loc: 19.776147842407227, scale: 1.879660725593567)\n",
            "\n",
            "Posterior Beta\n",
            "Normal(loc: 1.5615731477737427, scale: 0.11961106956005096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz5YS7TOeHo3",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:red\">Exercise 2: </span> \n",
        "\n",
        "Assume we also have a bunch of humidity senor measurements of the real humidity in the air, which is unknown. Then, assume the sales are also linearly influenced by the humidity. Extend the above model in order to integrate all of that.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAlOiwOIeHo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "e28597dc-1870-42dc-fb88-05dfc220ade8"
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]),\n",
        "       'sales': torch.tensor([46., 47., 49., 44., 50., 54., 51., 52., 49., 53.]),\n",
        "       'sensor_humidity': torch.tensor([82.8, 87.6, 69.1, 74.2, 80.3, 94.2, 91.2, 92.2, 99.1, 93.2])}\n",
        "\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
        "    ## Introduce a random variable \"humidity_mean\"\n",
        "\n",
        "    alpha = pyro.sample('alpha', dist.Normal(0.0, 100.0))\n",
        "    beta = pyro.sample('beta', dist.Normal(0.0, 100.0))\n",
        "    \n",
        "    ## Introduce a coefficient for the humidity \"gamma\"\n",
        "\n",
        "    with pyro.plate('a', obs['sensor'].shape[0]):\n",
        "        temp = pyro.sample('temp', dist.Normal(mean_temp, 2.0))\n",
        "        sensor = pyro.sample('sensor', dist.Normal(temp, 1.0), obs=obs['sensor'])\n",
        "        #Add the 'humidity' variable and the 'sensor_humidity' variable\n",
        "        \n",
        "        #Add the linear dependency of humidity\n",
        "        sales = pyro.sample('sales', dist.Poisson(????), obs=obs['sales'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-701ec1829cba>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    sales = pyro.sample('sales', dist.Poisson(????), obs=obs['sales'])\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehgJ35yGeHo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Auxiliary Guide Code\n",
        "def guide(obs):\n",
        "    mean = pyro.param(\"mean\", torch.mean(obs['sensor']))\n",
        "    scale = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(mean, scale))\n",
        "\n",
        "    meanH = pyro.param(\"meanH\", torch.mean(obs['sensor_humidity']))\n",
        "    scaleH = pyro.param(\"scaleH\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    humidity_mean = pyro.sample('humidity_mean', dist.Normal(meanH, scaleH))\n",
        "\n",
        "\n",
        "    alpha_mean = pyro.param(\"alpha_mean\", torch.mean(obs['sensor']), constraint=constraints.positive)\n",
        "    alpha_scale = pyro.param(\"alpha_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    alpha = pyro.sample('alpha', dist.Normal(alpha_mean, alpha_scale))\n",
        "\n",
        "    beta_mean = pyro.param(\"beta_mean\", torch.tensor(1.0), constraint=constraints.positive)\n",
        "    beta_scale = pyro.param(\"beta_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    beta = pyro.sample('beta', dist.Normal(beta_mean, beta_scale))\n",
        "\n",
        "    gamma_mean = pyro.param(\"gamma_mean\", torch.tensor(1.0), constraint=constraints.positive)\n",
        "    gamma_scale = pyro.param(\"gamma_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    gamma = pyro.sample('gamma', dist.Normal(gamma_mean, gamma_scale))\n",
        "\n",
        "    with pyro.plate('a', obs['sensor'].shape[0]) as i:\n",
        "        mean_i = pyro.param('mean_i', obs['sensor'][i])\n",
        "        scale_i = pyro.param('scale_i', torch.tensor(1.), constraint=constraints.positive)\n",
        "        temp = pyro.sample('temp', dist.Normal(mean_i, scale_i))\n",
        "        meanH_i = pyro.param('meanH_i', obs['sensor_humidity'][i])\n",
        "        scaleH_i = pyro.param('scaleH_i', torch.tensor(1.), constraint=constraints.positive)\n",
        "        humidity = pyro.sample('humidity', dist.Normal(meanH_i, scaleH_i)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4-Cg-QweHpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "d7839ed9-288f-4562-bc29-abe3c40902ce"
      },
      "source": [
        "#Run inference\n",
        "svi(model, guide, obs, num_steps=1000)\n",
        "\n",
        "#Print results    \n",
        "print(\"Posterior Temperature Mean\")\n",
        "print(dist.Normal(pyro.param(\"mean\").item(), pyro.param(\"scale\").item()))\n",
        "print(\"\")\n",
        "print(\"Posterior Humidity Mean\")\n",
        "print(dist.Normal(pyro.param(\"meanH\").item(), pyro.param(\"scaleH\").item()))\n",
        "print(\"\")\n",
        "print(\"Posterior Alpha\")\n",
        "print(dist.Normal(pyro.param(\"alpha_mean\").item(), pyro.param(\"alpha_scale\").item()))\n",
        "print(\"\")\n",
        "print(\"Posterior Beta\")\n",
        "print(dist.Normal(pyro.param(\"beta_mean\").item(), pyro.param(\"beta_scale\").item()))\n",
        "print(\"\")\n",
        "print(\"Posterior Gamma\")\n",
        "print(dist.Normal(pyro.param(\"gamma_mean\").item(), pyro.param(\"gamma_scale\").item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Posterior Temperature Mean\n",
            "Normal(loc: 19.290401458740234, scale: 0.6290149688720703)\n",
            "\n",
            "Posterior Humidity Mean\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c09fed0903d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Posterior Humidity Mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"meanH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scaleH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Posterior Alpha\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/primitives.py\u001b[0m in \u001b[0;36mparam\u001b[0;34m(name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[1;32m     59\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/runtime.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mam_i_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             msg = {\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/params/param_store.py\u001b[0m in \u001b[0;36mget_param\u001b[0;34m(self, name, init_tensor, constraint, event_dim)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minit_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/params/param_store.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconstrained\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnamed\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0munconstrained_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# compute the constrained value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'meanH'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3LOlV6_eHpE",
        "colab_type": "text"
      },
      "source": [
        "# 4.  Temporal Models\n",
        "\n",
        "If we think there is a temporal dependency between the variables, we can encode that easily with PPLs. \n",
        "\n",
        "Let's go back to our temperature-sensor model. Now, we assume that the real temperature must be similar to the real temperature in the previous time step. This temporal dependency can easily model as follows using a ``for-loop``. A graphical representation would be as follows,\n",
        "\n",
        "<img src=\"slides/Figures/tempmodel-temporal-III.png\" alt=\"Drawing\" style=\"width: 350px;\" >\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPCdK7CPeHpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1])}\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        if i==0:\n",
        "            temp = pyro.sample(f'temp_{i}', dist.Normal(mean_temp, 2.0))\n",
        "        else:\n",
        "            temp = pyro.sample(f'temp_{i}', dist.Normal(prev_temp, 2.0))\n",
        "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])\n",
        "        prev_temp = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLhvvUdKeHpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the guide\n",
        "def guide(obs):\n",
        "    mean = pyro.param(\"mean\", torch.mean(obs['sensor']))\n",
        "    scale = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(mean, scale))\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        mean_i = pyro.param(f'mean_{i}', obs['sensor'][i])\n",
        "        scale_i = pyro.param(f'scale_{i}', torch.tensor(1.), constraint=constraints.positive)\n",
        "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_i, scale_i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ83OvfoeHpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "        \n",
        "#Run inference\n",
        "svi(model, guide, obs, num_steps=2000)\n",
        "\n",
        "smooth_temp=[]\n",
        "for i in range(obs['sensor'].shape[0]):\n",
        "    smooth_temp.append(pyro.param(f'mean_{i}').item())\n",
        "\n",
        "print('Finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QZhkTkJeHpO",
        "colab_type": "text"
      },
      "source": [
        "Now we can plot the observered measurements of the temperature against the inferred real temperature by our model. We can see like the *recovered* temperature is much less noisy than the real one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sijXcYP_eHpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1], label='Sensor Temp')\n",
        "plt.plot(smooth_temp, label='Smooth Temp')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cay-rq6aeHpV",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:red\">Exercise 3: </span> \n",
        "\n",
        "Extends Excersise 2 by linking temporally the humidity measurements. Use the following graphical representation for reference, but consider here that the plate representation has to be coded in Pyro using a ``for-loop``.\n",
        "\n",
        "\n",
        "<img src=\"slides/Figures/icecream-model-temporal.png\" alt=\"Drawing\" style=\"width: 550px;\" >\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jQg9-IfeHpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The observatons   \n",
        "obs = {'sensor': torch.tensor([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1]),\n",
        "       'sales': torch.tensor([46., 47., 49., 44., 50., 54., 51., 52., 49., 53.]),\n",
        "       'sensor_humidity': torch.tensor([82.8, 87.6, 69.1, 74.2, 80.3, 94.2, 91.2, 92.2, 99.1, 93.2])/10.}\n",
        "\n",
        "\n",
        "\n",
        "def model(obs):\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(15.0, 2.0))\n",
        "    ## Introduce a random variable \"mean_humidity\"\n",
        "\n",
        "\n",
        "    alpha = pyro.sample('alpha', dist.Normal(0.0, 100.0))\n",
        "    beta = pyro.sample('beta', dist.Normal(0.0, 100.0))\n",
        "    ## Introduce a coefficient for the humidity \"gamma\"\n",
        "\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        if i==0:\n",
        "            temp = pyro.sample(f'temp_{i}', dist.Normal(mean_temp, 2.0))\n",
        "            #Introduce the 'humidity' variable at time 0.\n",
        "        else:\n",
        "            temp = pyro.sample(f'temp_{i}', dist.Normal(prev_temp, 2.0))\n",
        "            #Introduce the f'humidity_{i}' variable defining the transition\n",
        "            \n",
        "        sensor = pyro.sample(f'sensor_{i}', dist.Normal(temp, 1.0), obs=obs['sensor'][i])\n",
        "        #Introduce the f'sensor_humidity_{i}' variable. \n",
        "\n",
        "        sales = pyro.sample(f'sales_{i}', dist.Poisson(?????), obs=obs['sales'][i])\n",
        "        prev_temp = temp\n",
        "        #Keep humidity for the next time step. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_yNONXBeHpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the guide\n",
        "def guide(obs):\n",
        "    mean = pyro.param(\"mean\", torch.mean(obs['sensor']))\n",
        "    scale = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    mean_temp = pyro.sample('mean_temp', dist.Normal(mean, scale))\n",
        "\n",
        "    meanH = pyro.param(\"meanH\", torch.mean(obs['sensor_humidity']), constraint=constraints.positive)\n",
        "    scaleH = pyro.param(\"scaleH\", torch.tensor(1.), constraint=constraints.greater_than(0.01))\n",
        "    humidity_mean = pyro.sample('mean_humidity', dist.Normal(meanH, scaleH))\n",
        "\n",
        "\n",
        "    alpha_mean = pyro.param(\"alpha_mean\", torch.mean(obs['sensor']))\n",
        "    alpha_scale = pyro.param(\"alpha_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    alpha = pyro.sample('alpha', dist.Normal(alpha_mean, alpha_scale))\n",
        "\n",
        "    beta_mean = pyro.param(\"beta_mean\", torch.tensor(0.0))\n",
        "    beta_scale = pyro.param(\"beta_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    beta = pyro.sample('beta', dist.Normal(beta_mean, beta_scale))\n",
        "\n",
        "    gamma_mean = pyro.param(\"gamma_mean\", torch.tensor(0.0))\n",
        "    gamma_scale = pyro.param(\"gamma_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
        "    gamma = pyro.sample('gamma', dist.Normal(gamma_mean, gamma_scale))\n",
        "\n",
        "    for i in range(obs['sensor'].shape[0]):\n",
        "        mean_i = pyro.param(f'mean_{i}', obs['sensor'][i])\n",
        "        scale_i = pyro.param(f'scale_{i}', torch.tensor(1.), constraint=constraints.positive)\n",
        "        temp = pyro.sample(f'temp_{i}', dist.Normal(mean_i, scale_i))\n",
        "        meanH_i = pyro.param(f'meanH_{i}', obs['sensor_humidity'][i])\n",
        "        scaleH_i = pyro.param(f'scaleH_{i}', torch.tensor(1.), constraint=constraints.positive)\n",
        "        humidity_i = pyro.sample(f'humidity_{i}', dist.Normal(meanH_i, scaleH_i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtJAupQ_eHpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "        \n",
        "#Run inference\n",
        "svi(model, guide, obs, num_steps=2000)\n",
        "\n",
        "smooth_temp=[]\n",
        "smooth_humidity=[]\n",
        "\n",
        "for i in range(obs['sensor'].shape[0]):\n",
        "    smooth_temp.append(pyro.param(f'mean_{i}').item())\n",
        "    smooth_humidity.append(pyro.param(f'meanH_{i}').item())\n",
        "\n",
        "\n",
        "print('Finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgBDNN0AeHpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot([18., 18.7, 19.2, 17.8, 20.3, 22.4, 20.3, 21.2, 19.5, 20.1], label='Sensor Temp')\n",
        "plt.plot(smooth_temp, label='Smooth Temp')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFuDNueDeHpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "humidity = torch.tensor([82.8, 87.6, 69.1, 74.2, 80.3, 94.2, 91.2, 92.2, 99.1, 93.2])/10.\n",
        "plt.plot(humidity.detach().numpy(), label='Sensor Humidity')\n",
        "plt.plot(smooth_humidity, label='Smooth Humidity')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqKUU43xeHph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}